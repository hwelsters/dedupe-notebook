{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://complexity.asu.edu/sites/default/files/comses.jpg\" alt=\"comses.net's logo\" style=\"border: 4px solid  gray; display: flex; justify-content: center;\" height=200>\n",
    "\n",
    "# **Entity Resolution of Tags on ComSES.net using Dedupe**\n",
    "\n",
    "## **üöÄ Introduction** \n",
    "><br/>   \n",
    "> ‚ùì ComSES.net is a digital repository that supports discovery and good practices for software citation, digital preservation, reproducibility, and reuse.    <br/>\n",
    "> Visit it <a href=\"https://www.comses.net/\">here</a>   <br/>\n",
    "> <br/>\n",
    "\n",
    "<br/>\n",
    "On ComSES.net, tags play an important role. They allow users to search for codebases that they are interested in:\n",
    "<img src=\"public/tag-search.png\" alt=\"searching for tags\" style=\"border: 4px solid  gray; display: flex; justify-content: center;\">\n",
    "<sub> <strong>Figure 1. Searching for codebases using tags</strong> </sub>\n",
    "\n",
    "There is also a cool metrics page where researchers can see how the use of various technologies have changed over time:\n",
    "<img src=\"public/metrics-page.png\" alt=\"metrics page\" height=400 style=\"border: 4px solid  gray; display: flex; justify-content: center;\">\n",
    "\n",
    "<sub><strong> Figure 2. ComSES.net's awesome metrics page</strong></sub>\n",
    "\n",
    "Since there are a great number of technologies available to use for research computing, ComSES does not enforce any rules in the way codebases are tagged by researchers during the codebase creation phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **‚ùì Problem**\n",
    "Allowing researchers to write their own tags is wonderful since it allows researchers to better describe their codebase. However, a few problems arise from this scenario.\n",
    "- 1. Codebases with wrongly spelled / abbreviated tags are hard to search for.\n",
    "- 2. Different versions of the same technology aren't grouped together on ComSES.net's metrics page.\n",
    "  For example, on the metrics page, we would ideally like to treat NetLogo 6.1.1, NetLogo 6.2.1 and NetLogo 6.2.2 as the same thing and to display metrics accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **üïµÔ∏è‚Äç‚ôÄÔ∏è Existing strategies**\n",
    "### **1. NLTK's Porter Stemmer**\n",
    "\n",
    "\n",
    "> <br/>  \n",
    "> ‚ùì NLTK is a leading platform for building Python programs to work with human language data. <br/>\n",
    "> For more information, read the <a href=\"https://www.nltk.org\">documentation</a> for NLTK    <br/>\n",
    "> <br/>\n",
    "Use NLTK's porter stemmer to remove common suffixes and group tags accordingly.\n",
    "<img src=\"public/nltk-intro.png\" alt=\"your-image-description\" style=\"border: 4px solid  gray; display: flex; justify-content: center;\" height=200>\n",
    "<sub>**NLTK's porter-stemmer removing common suffixes to the word connect**</sub>\n",
    "\n",
    "Using the approach above, connect, connected, connection and connecting are treated as the same model. However, this method suffers from the problems identified in the **Problem** section.  \n",
    "**1. Small spelling mistakes have drastic consequences:**\n",
    "<img src=\"public/nltk-failure.png\" alt=\"your-image-description\" style=\"border: 4px solid  gray; display: flex; justify-content: center;\" height=200>\n",
    "<sub>**NLTK's porter-stemmer fails to account for spelling mistakes**</sub>\n",
    "\n",
    "**2. Different versions of the same software are not grouped accordingly:**\n",
    "<img src=\"public/nltk-versions.png\" alt=\"your-image-description\" style=\"border: 4px solid  gray; display: flex; justify-content: center;\" height=200>\n",
    "<sub>**Different versions of the same software are not grouped accordingly**</sub>\n",
    "\n",
    "### **2. Regex**\n",
    "> <br/>  \n",
    "> ‚ùì Regular expressions (regex) are concise patterns for text manipulation and matching.   <br/>\n",
    "> <br/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Use regex to group software of various version numbers.  \n",
    "This approach works reasonably well since most technologies have standard ways of specifying version numbers.\n",
    "\n",
    "However, this method is labor-intensive and requires programmers to write regular expressions for every single thing they would like grouped. ComSES.net currently has 3000+ tags in production so this is not ideal. Also, this means that every time a new technology shows up on ComSES.net, the programmers have to be notified to write a new regex for the technology. \n",
    "Again, this method also fails to account for small mispellings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **ü§ñ Using Machine Learning**\n",
    "We want to group similar tags. In machine learning, this task is called [entity resolution](https://www.ibm.com/docs/en/iii/9.0.0?topic=insight-entity-resolution). \n",
    "> <br/>  \n",
    "> ‚ùì Entity resolution is the process of identifying and merging   \n",
    "> duplicate or similar records in a dataset.   <br/>\n",
    "> <br/>\n",
    "\n",
    "After searching the web for various solutions, we found one that fit our specifications. \n",
    "<img src=\"public/dedupe-logo.png\" alt=\"your-image-description\" style=\"border: 4px solid  gray; display: flex; justify-content: center;\" height=150>\n",
    "\n",
    "Dedupe is wonderful because it accounts for mispellings and abbreviations.  \n",
    "It is also able to group similar versions together without requiring specialized regexes as long as it is provided enough training data.\n",
    "\n",
    "Taken straight from the website:   \n",
    "> <br/>  \n",
    "> ü§ì \"Dedupe.io is a powerful tool that learns the best way to find similar rows in your data. Using cutting-edge research in machine learning we quickly and accurately identify matches in your Excel spreadsheet or database‚Äîsaving you time and money.\"  \n",
    "> Check out the <a href=\"https://dedupe.io/\">website</a> for more information <br/>\n",
    "> <br/>\n",
    "\n",
    "Dedupe is both a SaaS and a Python library. We decided to use the Python library and took advantage of the following classes:\n",
    "- **Dedupe** - A class for active-learning deduplication. It clusters matching tags that it assumes maps to the same entity.\n",
    "- **Gazetteer** - A class for active learning gazetteer matching. It matches a messy data set against a 'canonical dataset'.\n",
    "\n",
    "## **‚≠ê Clustering**\n",
    "\n",
    "It is pretty easy to get started with using the `Dedupe` class.  \n",
    "You simply have to provide a list of columns and specify the variable type of each column:  \n",
    "In our case, we only had a single column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dedupe\n",
    "\n",
    "columns = [\n",
    "    {\"field\": \"name\", \"type\": \"String\"},\n",
    "]\n",
    "deduper = dedupe.Dedupe(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will use the following small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    0: {\"name\": \"agent-based model\"},\n",
    "    1: {\"name\": \"agent based model\"},\n",
    "    2: {\"name\": \"ajent base moder (abms)\"},\n",
    "    3: {\"name\": \"comses\"},\n",
    "    4: {\"name\": \"comses.net\"},\n",
    "    5: {\"name\": \"NetLogo 6.1.1\"},\n",
    "    6: {\"name\": \"NetLogo 6.1.2\"},\n",
    "    7: {\"name\": \"NetLogo 6.2.1\"},\n",
    "    8: {\"name\": \"C#\"},\n",
    "    9: {\"name\": \"C++15\"},\n",
    "    10: {\"name\": \"C++16\"},\n",
    "    11: {\"name\": \"C++17\"},\n",
    "    12: {\"name\": \"The University of Waterloo\"},\n",
    "    13: {\"name\": \"Arizona State University\"},\n",
    "    14: {\"name\": \"Arizona International University\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dedupe requires us to pass in a list of data that the model will use.  \n",
    "We do that here:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduper.prepare_training(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **üí™ Training the clustering model**\n",
    "To start out, you also have to provide Dedupe with pairs of tags that should be mapped together.  \n",
    "The Dedupe class has a simple function which returns the pair of tags that it is most uncertain about:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'name': 'comses'}, {'name': 'comses.net'})]\n"
     ]
    }
   ],
   "source": [
    "pair = deduper.uncertain_pairs()\n",
    "print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, you pass the label back into the model like so. Since both the tags above match, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_examples = {\n",
    "    \"match\": pair,\n",
    "    \"distinct\": [\n",
    "    ],\n",
    "}\n",
    "deduper.mark_pairs(labeled_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a nifty little console labelling function that dedupe provides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe.console_label(deduper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After labelling enough instances, you can start training the model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduper.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **‚ú®Clustering‚ú®**\n",
    "You would definitely need to label a few more instances before your model can start working.  \n",
    "Once you are done with this, you can move on to the true magic. You pass in a list of records you would like to cluster and set a threshold.\n",
    "Your list of records should be formatted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    0: {'name': 'agents'},\n",
    "    1: {'name': 'agent-based models'},\n",
    "    2: {'name': 'agent-based models (abms)'},\n",
    "    3: {'name': 'agent-based model'},\n",
    "    4: {'name': 'agants'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 4), (0.96180147, 0.96180147)),\n",
       " ((1, 2, 3), array([0.99858896, 0.99842318, 0.99854703]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = deduper.partition(data, threshold=0.5)\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It isn't immediately clear what the output means but the tuples returned are:\n",
    "(list of ids of records that are grouped together, list of confidence values for each id).\n",
    "We use a nifty little function for displaying the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUP 0\n",
      "{'name': 'agents'}\n",
      "{'name': 'agants'}\n",
      "\n",
      "\n",
      "GROUP 1\n",
      "{'name': 'agent-based models'}\n",
      "{'name': 'agent-based models (abms)'}\n",
      "{'name': 'agent-based model'}\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def display_clusters(partitions):\n",
    "    for index, partition in enumerate(partitions):\n",
    "        print(f\"GROUP {index}\")\n",
    "        for element in partition[0]:\n",
    "            print(data[element])\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(display_clusters(duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ **That's all in terms of clustering, let's move on to gazetteering now!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **‚≠ê Canonicalization / Gazetteering**\n",
    "\n",
    "It is pretty easy to get started with using the `Dedupe` class.  \n",
    "You simply have to provide a list of columns and specify the variable type of each column:  \n",
    "In our case, we only had a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    {'field' : 'name', 'type': 'String'},\n",
    "]\n",
    "gazetteer = dedupe.Gazetteer(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following small dataset for the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    0: {\"name\": \"C# 12\"},\n",
    "    1: {\"name\": \"C# 11\"},\n",
    "    2: {\"name\": \"C++ 17\"},\n",
    "    3: {\"name\": \"C++ 18\"},\n",
    "    4: {\"name\": \"Java 19\"},\n",
    "    5: {\"name\": \"Java 12\"},\n",
    "}\n",
    "\n",
    "canonical_data = {\n",
    "    6: {\"name\": \"C#\"},\n",
    "    7: {\"name\": \"C++\"},\n",
    "    8: {\"name\": \"Java\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first prepare the training data similar to what we did to Dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazetteer.prepare_training(data, canonical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üí™ Training the model**\n",
    "To start out, you also have to provide Gazetteer with pairs of tags that should be mapped together.  \n",
    "The Gazetteer class has a simple function which returns the pair of tags that it is most uncertain about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'name': 'C++ 17'}, {'name': 'C++'})]\n"
     ]
    }
   ],
   "source": [
    "pair = gazetteer.uncertain_pairs()\n",
    "print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, you pass the label back into the model like so. Since both the tags above match, we do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_examples = {\n",
    "    \"match\": pair,\n",
    "    \"distinct\": [\n",
    "    ],\n",
    "}\n",
    "gazetteer.mark_pairs(labeled_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the Dedupe class, there's also a nifty little console label function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe.console_label(gazetteer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the model on the labelled data like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gazetteer.train()\n",
    "gazetteer.index(canonical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ü§ì Canonicalization / Gazetteering**\n",
    "You pass in a list of records you would like to map to the canonical list before.\n",
    "Your list of records should be formatted as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    0: {\"name\": \"C# 12\"},\n",
    "    1: {\"name\": \"C# 11\"},\n",
    "    2: {\"name\": \"C++ 17\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ((6, 0.821512),)), (1, ((6, 0.821512),)), (2, ((7, 0.8383985),))]\n"
     ]
    }
   ],
   "source": [
    "matches = gazetteer.search(test_data, threshold=0.5)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It isn't immediately clear what the value returns is. \n",
    "(id from test_data, (array of tuple of matches the first value is the id from canonical_data and the second is the confidence))\n",
    "We made a nifty little visualizer for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG: {'name': 'C# 12'}   CANONICAL TAG: {'name': 'C#'}\n",
      "TAG: {'name': 'C# 11'}   CANONICAL TAG: {'name': 'C#'}\n",
      "TAG: {'name': 'C++ 17'}   CANONICAL TAG: {'name': 'C++'}\n"
     ]
    }
   ],
   "source": [
    "def display_gazetteer_results(matches):\n",
    "    for match in matches:\n",
    "        print(\"TAG:\", test_data[match[0]], \"  CANONICAL TAG: \", end=\"\")\n",
    "        for canonical_tag in match[1]:\n",
    "            print(canonical_data[canonical_tag[0]], end = \"\")\n",
    "        print(\"\")\n",
    "display_gazetteer_results(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üî® Workflow**\n",
    "Using these classes, we implemented a reasonably simple workflow for a curator to cluster the tags.\n",
    "\n",
    "First, the curator clusters the tags:  \n",
    "![Alt text](public/dedupe-workflow.png)  \n",
    "<sub>Diagram for the human in the loop workflow for clustering</sub>\n",
    "\n",
    "<br/>\n",
    "\n",
    "However, after creating the initial canonical list, it's usually a better idea to use the gazetteer to map new tags to the canonical list.\n",
    "This workflow is fairly similar to the one for clustering:  \n",
    "![Alt text](public/gazetteer-workflow.png)  \n",
    "<sub>Diagram for the human in the loop workflow for gazetteering</sub>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üôå Conclusion**\n",
    "In conclusion, we've covered all the essential aspects of tag deduplication. By eliminating duplicate tags, you can streamline your data, improve organization, and enhance the overall efficiency of your projects or systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
